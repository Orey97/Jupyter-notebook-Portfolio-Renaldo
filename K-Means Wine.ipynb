{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We load the dataseset vino.txt that contains wine correlated data\n",
    "vino = pd.read_csv('vino.txt', delim_whitespace=True)\n",
    "print(vino.info())\n",
    "print(vino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1559 wines and 6 variables**\n",
    "1. **Fixed Acidity**: This is the portion consisting of the acidic substances present in a wine that are not volatilized but remain in the wine throughout its life. Being one of the fundamental parameters of wine, it determines the harvest period.\n",
    "2. **Total Sulfur Dioxide**: This is the amount of free sulfur dioxide (SO2, sulfur dioxide) plus that bound to other chemical agents such as aldehydes, pigments, or sugars. It is the main additive used in oenology to prevent wine spoilage.\n",
    "3. **pH**: This represents an index of real acidity. It is a parameter that undergoes variations during the various stages of winemaking and storage.\n",
    "4. **Sulfites**: These are added to promote preservation. They possess antioxidant and antimicrobial properties that protect the wine from bacterial damage.\n",
    "5. **Alcohol Content**: Indicates the percentage of alcohol by volume.\n",
    "6. **Satisfaction Rating**: 1 = dissatisfied, 2 = satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to convert Grad into categorical data\n",
    "vino['Grad'] = vino['Grad'].astype('category')\n",
    "print(vino.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploratory Data Analysis to understand the dataset\n",
    "print('Summary statistics:\\n')\n",
    "print(vino.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have to Standardize the quantitative variables (all exept Grad), basicly the first 5 columns\n",
    "vino2 = vino.iloc[:, 0:5].values\n",
    "scaler = StandardScaler()\n",
    "vino_std = scaler.fit_transform(vino2)\n",
    "\n",
    "print(vino_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We ne to perform euclidean distance and construct the matrix to find the optimal number of clusters\n",
    "matrix = pairwise_distances(vino_std, metric='euclidean')\n",
    "print(matrix)\n",
    "\n",
    "\n",
    "#The dimension of the matrix of the dij observaions will be 1599X1599, lets take a look at the first 5 rows and columns\n",
    "matrix5 = matrix[:5,:5]\n",
    "print('Lets consider first 5 raws and columns:\\n')\n",
    "print(matrix5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's start the iterative process of k-means with a k=2\n",
    "kmeans2 = KMeans(n_clusters = 2, n_init=20, random_state = 42)\n",
    "\n",
    "#This parameter tells the algorithm to run the entire clustering process 20 different times, each with different random initializations,\n",
    "#and then select the best result (the one with the lowest inertia or within-cluster sum of squares).\n",
    "#By setting a specific value (like 42), you'll get the same results each time you run the algorithm. This is important for consistency in analysis and debugging.\n",
    "\n",
    "kmeans2.fit(vino_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's talk about the output of the clustering process \n",
    "print('Cluster Size:\\n')\n",
    "print(pd.Series(kmeans2.labels_).value_counts())\n",
    "print('\\nCluster Centers:\\n')\n",
    "print(kmeans2.cluster_centers_)\n",
    "\n",
    "#Let's add a column to the dataset with the cluster labels (0 or 1)\n",
    "vino['Cluster'] = kmeans2.labels_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We analyze the statistics of each cluster and compare them\n",
    "print('Summary of statistics by Cluster:\\n')\n",
    "for cluster_label in np.unique(vino['Cluster']):\n",
    "    print(f'Cluster{cluster_label}:')\n",
    "    print(vino[vino['Cluster'] == cluster_label].describe())\n",
    "\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validate clustering quality\n",
    "# We use the silhouette score \n",
    "silhouette_avg = silhouette_score(vino_std, kmeans2.labels_, metric='euclidean')\n",
    "print('silhouette score for k=2:', silhouette_avg)\n",
    "\n",
    "#The value is not good let's try to use the WSS (within-cluster sum of squares)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's define the WSS function\n",
    "def Wss(k):\n",
    "    kmeans_model = KMeans(n_clusters=k, n_init=20, random_state=42)\n",
    "    kmeans_model.fit(vino_std)\n",
    "    return kmeans_model.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elbow method: how yo choose the best k\n",
    "ks = range(1,11)\n",
    "wss_values = [Wss(k) for k in ks]\n",
    "\n",
    "plt.plot(ks, wss_values, marker='o')\n",
    "plt.xlabel('Group number (k)')\n",
    "plt.ylabel('within-cluster sum of squares (Wss)')\n",
    "plt.title('Elbow Methods')\n",
    "plt.show()\n",
    "\n",
    "#The WSS starts very high (around 8000) with k=1\n",
    "#There's a sharp drop when moving from k=1 to k=2 (down to about 6100)\n",
    "#The curve continues to decrease but at a decreasing rate\n",
    "#The elbow point appears to be around k=4 or k=5, where the curve begins to flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's evalute k=4, k=5 or k=6\n",
    "k_values = [4, 5, 6 ]\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, n_init=20, random_state=42)\n",
    "    kmeans.fit(vino_std)\n",
    "    silhouette_avg = silhouette_score(vino_std, kmeans.labels_, metric='euclidean')\n",
    "    print(f'Silohouette score for k={k}: {silhouette_avg}')\n",
    "\n",
    "\n",
    "#We can notice the best value is for k=5 on 0.242\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
